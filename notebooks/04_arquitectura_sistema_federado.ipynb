{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "650e616c",
   "metadata": {},
   "source": [
    "# 04 · Arquitectura del sistema de aprendizaje federado\n",
    "\n",
    "En este notebook el objetivo es definir la arquitectura que vamos a usar para el aprendizaje federado (FL) sobre el problema de: **Predicción de muerte prematura por Enfermedades No Transmisibles (ENT / NCD)** usando el Registro de Defunciones 2023 de Ecuador.\n",
    "\n",
    "La idea es que este notebook sirva para documentar:\n",
    "\n",
    "- Cómo se organiza el sistema (topologías).\n",
    "- Qué rol tiene cada nodo (cliente / servidor / agregador).\n",
    "- Qué mensajes van a viajar por la red.\n",
    "- Cómo vamos a serializar y deserializar parámetros del modelo.\n",
    "- Cómo se sincronizan las rondas globales de entrenamiento.\n",
    "- Qué estrategias de agregación vamos a comparar.\n",
    "\n",
    "Aquí solo definimos las decisiones de diseño para luego implementarlas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a3fed4",
   "metadata": {},
   "source": [
    "## 1. Contexto del problema\n",
    "\n",
    "Trabajamos con el **Registro de Defunciones 2023** de Ecuador (INEC) para construir un problema de clasificación binaria centrado en un indicador de alto valor en salud pública: **mortalidad prematura por Enfermedades No Transmisibles (ENT / NCD)**, alineado con el estándar oficial **SDG 3.4.1** de Naciones Unidas.\n",
    "\n",
    "### ¿Qué estamos prediciendo?\n",
    "\n",
    "Definimos la variable objetivo `is_premature_ncd` según la regla:\n",
    "\n",
    "| Condición                                                                 | Resultado |\n",
    "|---------------------------------------------------------------------------|-----------|\n",
    "| Edad entre **30 y 69 años** **y** causa pertenece a uno de los 4 grupos NCD (cardiovascular, cáncer, diabetes o respiratorias crónicas) | 1 |\n",
    "| Cualquier otro caso                                                       | 0 |\n",
    "\n",
    "Para esto:\n",
    "\n",
    "- Convertimos todas las edades a **años (`edad_anos`)**, combinando la edad reportada con su unidad (`cod_edad`: años, meses, días, horas).\n",
    "- Usamos `causa103` (nivel intermedio recomendado por INEC) para asignar cada registro a uno de estos grupos:\n",
    "  - `Cardiovascular`\n",
    "  - `Cancer`\n",
    "  - `Diabetes`\n",
    "  - `Chronic_Respiratory`\n",
    "  - `No_NCD` (otras causas: infecciosas, perinatales, violentas, accidentes, etc.)\n",
    "\n",
    "### ¿Por qué este enfoque?\n",
    "\n",
    "Porque este indicador es **uno de los más vigilados a nivel global**. La OMS lo usa para medir la calidad del sistema de salud, inequidades territoriales y progreso hacia la reducción de muertes evitables.  \n",
    "\n",
    "Con este problema podemos responder preguntas clave para un país:\n",
    "\n",
    "- ¿En qué territorios y establecimientos se concentran las muertes prematuras por ENT?\n",
    "- ¿Qué perfiles demográficos están más expuestos?\n",
    "- ¿Cómo varían los patrones entre hospitales o provincias sin compartir datos sensibles?\n",
    "\n",
    "Esto último es **precisamente** donde entra el Aprendizaje Federado.\n",
    "\n",
    "### ¿Qué hicimos en el notebook anterior (03)?\n",
    "\n",
    "Ya construimos todo lo necesario para arrancar el sistema federado:\n",
    "\n",
    "- Pipeline de preprocesamiento (imputación, one-hot, escalado).\n",
    "- División estratificada train / validación / test.\n",
    "- Entrenamiento de tres modelos simples:\n",
    "  - `LogisticRegression`\n",
    "  - `MLPClassifier`\n",
    "  - `SGDClassifier`\n",
    "- Entrenamiento de un **Random Forest** centralizado fuerte.\n",
    "- Calibración de umbrales para maximizar **F1**, que es la métrica más coherente con el objetivo (detectar la mayor cantidad posible de muertes prematuras sin inflar falsos positivos).\n",
    "\n",
    "Resultados principales:\n",
    "\n",
    "- El **Random Forest** fue el mejor modelo centralizado (baseline país completo).\n",
    "- El **MLPClassifier** fue el mejor modelo simple y será nuestro **modelo base federado**.\n",
    "- También guardamos una baseline lineal con Regresión Logística.\n",
    "\n",
    "Modelos guardados:\n",
    "\n",
    "- `premature_ncd_centralized_best.joblib`  \n",
    "- `premature_ncd_federated_baseline.joblib`  \n",
    "- `logreg_premature_ncd_centralized_baseline.joblib`\n",
    "\n",
    "\n",
    "### ¿Qué resolvemos con este trabajo? (Importancia y aporte)\n",
    "\n",
    "Este proyecto propone un enfoque **moderno, aplicado y directamente útil para salud pública en Ecuador**:\n",
    "\n",
    "1. **Modelamos un indicador clave (SDG 3.4.1)** que mide muertes prematuras por ENT, completamente alineado con estándares OMS/ONU.\n",
    "2. **Aprovechamos el registro nacional de defunciones**, obteniendo un modelo centralizado fuerte que puede ayudar a entender patrones de mortalidad.\n",
    "3. **Diseñamos una arquitectura de aprendizaje federado**, donde los “hospitales” pueden entrenar modelos colaborativamente **sin compartir datos sensibles**.\n",
    "4. **Demostramos cómo se comporta el modelo centralizado en cada hospital**, mostrando la heterogeneidad real (datos no-IID), un problema clásico donde el FL tiene ventajas.\n",
    "\n",
    "**Nuestro aporte es mostrar que Ecuador puede entrenar modelos predictivos de mortalidad prematura por ENT sin centralizar datos sensibles, usando un sistema federado compatible con hospitales reales.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb72e99",
   "metadata": {},
   "source": [
    "## 2. Objetivo\n",
    "\n",
    "Vamos a **documentar la arquitectura** del sistema que vamos a implementar luego en código.\n",
    "\n",
    "En concreto, dejamos definidos:\n",
    "\n",
    "1. **Topologías a comparar**\n",
    "   - Aprendizaje **centralizado clásico** (ya implementado).\n",
    "   - **Federated Learning centralizado** (un servidor de agregación fijo).\n",
    "   - **Federated Learning semi-descentralizado** (el rol de agregador rota entre nodos).\n",
    "   - Boceto de un escenario **totalmente descentralizado** (peer-to-peer).\n",
    "\n",
    "2. **Nodos y datos**\n",
    "   - Cómo definimos cada \"hospital cliente\" a partir del dataset.\n",
    "   - Por qué los datos quedan **no-IID** (no independientes ni idénticamente distribuidos) entre nodos.\n",
    "\n",
    "3. **Roles y responsabilidades**\n",
    "   - Cliente federado.\n",
    "   - Servidor central (para FL centralizado).\n",
    "   - Nodo agregador dinámico (para FL semi-descentralizado).\n",
    "\n",
    "4. **Mensajes y protocolo de comunicación**\n",
    "   - Qué tipos de mensajes existen (INIT, UPDATE, AGGREGATED, etc.).\n",
    "   - Qué campos lleva cada mensaje.\n",
    "   - Cómo serializamos parámetros (JSON con listas anidadas a partir de NumPy).\n",
    "\n",
    "5. **Rondas globales y sincronización**\n",
    "   - Cómo se organiza una ronda global de FL.\n",
    "   - Cuándo se considera que una ronda está \"completa\".\n",
    "   - Qué pasa si un nodo no responde.\n",
    "\n",
    "6. **Estrategias de agregación**\n",
    "   - **FedAvg ponderado por número de muestras**.\n",
    "   - **Promedio simple (no ponderado)** como estrategia alternativa.\n",
    "\n",
    "7. **Métricas para comparar arquitecturas**\n",
    "   - Accuracy, F1, ROC AUC, tiempos de entrenamiento y costo de comunicación.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55206981",
   "metadata": {},
   "source": [
    "## 3. Definición de nodos y escenario no-IID\n",
    "\n",
    "### 3.1. Cómo definimos los \"hospitales clientes\"\n",
    "\n",
    "Nuestro dataset limpio tiene columnas de contexto territorial y de establecimiento, entre ellas:\n",
    "\n",
    "- `prov_fall`  → provincia de fallecimiento\n",
    "- `cant_fall`  → cantón de fallecimiento\n",
    "- `lugar_ocur` → tipo de establecimiento donde ocurrió la muerte\n",
    "\n",
    "En lugar de contar con un identificador explícito de hospital, definimos un **\"hospital cliente\"** como una combinación frecuente de:\n",
    "\n",
    "> `hospital_cliente = (prov_fall, cant_fall, lugar_ocur)`\n",
    "\n",
    "En el notebook 02 ya se construyó un dataset `defunciones_2023_ncd_hosp_clients.csv` donde:\n",
    "\n",
    "- Se filtraron las combinaciones más frecuentes (los hospitales \"grandes\").\n",
    "- Se seleccionaron **3 hospitales clientes principales**:\n",
    "  - `Hospital_1`\n",
    "  - `Hospital_2`\n",
    "  - `Hospital_3`\n",
    "- Cada uno tiene miles de registros, con tasas de clase positiva (`is_premature_ncd = 1`) distintas.\n",
    "\n",
    "Esto nos da un escenario natural para aprendizaje federado:\n",
    "\n",
    "- Cada *nodo cliente* simula un hospital con su propio subconjunto de defunciones.\n",
    "- La distribución de características y de la clase no es la misma entre nodos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e08fbcfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hospital_cliente</th>\n",
       "      <th>n_samples</th>\n",
       "      <th>positive_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hospital_1</td>\n",
       "      <td>5530</td>\n",
       "      <td>0.163472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hospital_2</td>\n",
       "      <td>3003</td>\n",
       "      <td>0.169497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hospital_3</td>\n",
       "      <td>2368</td>\n",
       "      <td>0.139780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hospital_cliente  n_samples  positive_rate\n",
       "0       Hospital_1       5530       0.163472\n",
       "1       Hospital_2       3003       0.169497\n",
       "2       Hospital_3       2368       0.139780"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "DATA_PROCESSED = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "\n",
    "hosp_path = DATA_PROCESSED / \"defunciones_2023_ncd_hosp_clients.csv\"\n",
    "df_hosp_clients = pd.read_csv(hosp_path)\n",
    "\n",
    "df_hosp_clients[\"is_premature_ncd\"] = df_hosp_clients[\"is_premature_ncd\"].astype(int)\n",
    "\n",
    "summary_by_hosp = (\n",
    "    df_hosp_clients\n",
    "    .groupby(\"hospital_cliente\")[\"is_premature_ncd\"]\n",
    "    .agg([\"count\", \"mean\"])\n",
    "    .rename(columns={\"count\": \"n_samples\", \"mean\": \"positive_rate\"})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "summary_by_hosp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d08742",
   "metadata": {},
   "source": [
    "La tabla anterior muestra, para cada hospital cliente:\n",
    "\n",
    "- `n_samples`      → cuántas defunciones aporta ese nodo.\n",
    "- `positive_rate`  → proporción de muertes prematuras por NCD (**tasa de clase positiva**).\n",
    "\n",
    "Tenemos algo como esto:\n",
    "\n",
    "| hospital_cliente | n_samples | positive_rate |\n",
    "|------------------|-----------|---------------|\n",
    "| Hospital_1       | 5530      | ≈ 0.16        |\n",
    "| Hospital_2       | 3003      | ≈ 0.17        |\n",
    "| Hospital_3       | 2368      | ≈ 0.14        |\n",
    "\n",
    "Esto confirma que:\n",
    "\n",
    "- Cada nodo tiene un **tamaño de muestra distinto** (desbalance en cantidad de datos).\n",
    "- Las **tasas de clase positiva son distintas**, es decir, los nodos no ven la misma proporción de muertes prematuras por NCD.\n",
    "\n",
    "Es un escenario claramente **no-IID**, alineado con lo que se observa en la práctica cuando se trabaja con hospitales reales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54df0aea",
   "metadata": {},
   "source": [
    "## 4. Topologías del sistema a comparar\n",
    "\n",
    "En este proyecto vamos a comparar explícitamente tres configuraciones:\n",
    "\n",
    "1. **Aprendizaje centralizado clásico** (baseline).\n",
    "2. **Aprendizaje federado centralizado** (un servidor de agregación fijo).\n",
    "3. **Aprendizaje federado semi-descentralizado** (el agregador rota entre nodos).\n",
    "\n",
    "Y dejaremos un bosquejo para un posible **FL totalmente descentralizado** (peer-to-peer).\n",
    "\n",
    "A continuación describimos cada topología."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1461deba",
   "metadata": {},
   "source": [
    "### 4.1. Aprendizaje centralizado clásico (baseline)\n",
    "\n",
    "Este es el escenario que ya implementamos en el notebook 03:\n",
    "\n",
    "- Todo el dataset limpio 2023 (o el subconjunto elegido) se carga en un **solo servidor**.\n",
    "- Entrenamos un modelo centralizado (Random Forest, en nuestro caso) con acceso a **todas las muestras**.\n",
    "- Evaluamos el desempeño en un conjunto de test estratificado.\n",
    "\n",
    "En términos de arquitectura:\n",
    "\n",
    "- No hay comunicación entre nodos.\n",
    "- No hay privacidad por diseño: todos los registros se centralizan.\n",
    "\n",
    "Este escenario sirve como **upper bound** de desempeño: nos dice qué tan bien podemos hacerlo cuando no hay restricciones de privacidad ni de reparto de datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e833f694",
   "metadata": {},
   "source": [
    "### 4.2. Federated Learning centralizado (un servidor fijo)\n",
    "\n",
    "En el escenario de **FL centralizado**:\n",
    "\n",
    "- Tenemos un **servidor de agregación** fijo (puede estar en la misma máquina donde corrimos el modelo centralizado, pero lógicamente es otro rol).\n",
    "- Cada **nodo cliente** (Hospital_1, Hospital_2, Hospital_3) mantiene localmente su fragmento de datos.\n",
    "- El entrenamiento ocurre en **rondas globales**. En cada ronda:\n",
    "\n",
    "  1. El servidor envía a cada cliente el **modelo global actual** (sus parámetros).\n",
    "  2. Cada cliente:\n",
    "     - Carga los parámetros recibidos.\n",
    "     - Entrena localmente durante `E` épocas sobre sus datos.\n",
    "     - Envía de vuelta al servidor sus **parámetros actualizados** y el número de muestras usadas (`n_samples`).\n",
    "  3. El servidor espera a recibir las actualizaciones de todos (o de una fracción) de los clientes.\n",
    "  4. El servidor aplica una **regla de agregación** (por ejemplo, FedAvg) sobre los parámetros recibidos.\n",
    "  5. El servidor actualiza el modelo global y repite el proceso en la siguiente ronda.\n",
    "\n",
    "En esta topología, el servidor es:\n",
    "\n",
    "- El **único punto de agregación**.\n",
    "- La **única fuente de verdad** del modelo global.\n",
    "- Responsable de registrar métricas por ronda y de coordinar la sincronización.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0698003",
   "metadata": {},
   "source": [
    "### 4.3. Federated Learning semi-descentralizado (agregador rotativo)\n",
    "\n",
    "En el escenario **semi-descentralizado**:\n",
    "\n",
    "- Eliminamos el **servidor fijo** como componente lógico.\n",
    "- En cada ronda elegimos **uno de los nodos clientes** para que actúe como **agregador temporal**.\n",
    "- La elección del agregador puede seguir distintas políticas:\n",
    "  - **Round-robin**: en la ronda 1 el agregador es el Hospital_1, en la 2 el Hospital_2, en la 3 el Hospital_3, y se repite.\n",
    "  - **Mejor desempeño local**: elegimos como agregador el nodo que haya obtenido mejor F1 en la ronda anterior.\n",
    "  - **Selección aleatoria**, con probabilidad uniforme o ponderada.\n",
    "\n",
    "Para este proyecto vamos a usar una política **simple y reproducible**:\n",
    "\n",
    "> **Round-robin entre los 3 hospitales clientes.**\n",
    "\n",
    "Flujo por ronda:\n",
    "\n",
    "1. Elegimos un **agregador actual** `A_t` (por ejemplo, Hospital_2).\n",
    "2. `A_t` envía el modelo global de referencia a los demás nodos.\n",
    "3. Todos los nodos (incluyendo `A_t`) entrenan localmente durante `E` épocas.\n",
    "4. Los nodos envían sus parámetros actualizados a `A_t` junto con `n_samples`.\n",
    "5. `A_t` agrega los parámetros (por ejemplo, usando FedAvg).\n",
    "6. `A_t` difunde el modelo global actualizado a todos los nodos.\n",
    "\n",
    "\n",
    "Observaciones:\n",
    "\n",
    "- Lógicamente el sistema sigue siendo **centralizado por ronda**, pero el rol de agregador **se mueve** entre nodos.\n",
    "- Esto permite estudiar un escenario más cercano a una red **entre pares** donde no hay un servidor fijo privilegiado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae8fb87",
   "metadata": {},
   "source": [
    "### 4.4. Boceto de un FL completamente descentralizado (peer-to-peer)\n",
    "\n",
    "Como extensión conceptual, podemos mencionar una topología **peer-to-peer** donde:\n",
    "\n",
    "- No existe ningún servidor ni agregador designado.\n",
    "- Cada nodo intercambia parámetros directamente con algunos vecinos según una **topología de red** (por ejemplo, un anillo o un grafo aleatorio).\n",
    "- El modelo se va mezclando a través de rondas de comunicación local (algoritmos tipo gossip).\n",
    "\n",
    "En este proyecto **no vamos a implementar** esta variante, pero podemos plantearla como futuro trabajo:\n",
    "\n",
    "- Nuestro modelo base MLP se podría entrenar en un **anillo de hospitales**, donde cada hospital promedia su modelo con el de su vecino en cada ronda.\n",
    "- El paper puede incluir un pequeño esquema conceptual y discutir los retos: convergencia más lenta, necesidad de múltiples pasos de gossip, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad7ebef",
   "metadata": {},
   "source": [
    "## 5. Roles en el sistema: cliente, servidor y agregador\n",
    "\n",
    "### 5.1. Cliente federado (hospital)\n",
    "\n",
    "Cada **cliente federado** representa un hospital (o grupo de hospitales) con su propio subconjunto de datos:\n",
    "\n",
    "- Tiene acceso **únicamente** a sus registros de defunciones.\n",
    "- Nunca envía datos crudos (ni variables sensibles) a otros nodos.\n",
    "- Solo comparte **parámetros del modelo** y metadatos agregados.\n",
    "\n",
    "Responsabilidades principales:\n",
    "\n",
    "1. **Cargar el modelo base federado** (MLP) y el pipeline de preprocesamiento desde el modelo `premature_ncd_federated_baseline.joblib`.\n",
    "2. **Recibir parámetros iniciales** del modelo global.\n",
    "3. **Reemplazar** los parámetros de su modelo local con los parámetros globales recibidos.\n",
    "4. Entrenar localmente durante `E` épocas con sus datos (`X_h`, `y_h`).\n",
    "5. **Medir métricas locales** (F1, accuracy, etc.) en un conjunto de validación local.\n",
    "6. **Enviar al agregador**:\n",
    "   - Sus parámetros actualizados.\n",
    "   - `n_samples` usados en el entrenamiento.\n",
    "   - Opcionalmente, métricas locales para monitoreo.\n",
    "7. Recibir el nuevo modelo global y repetir el proceso en la siguiente ronda.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9a6db8",
   "metadata": {},
   "source": [
    "### 5.2. Servidor central (solo en FL centralizado)\n",
    "\n",
    "El **servidor central** aparece únicamente en la topología de FL centralizado.\n",
    "\n",
    "Responsabilidades:\n",
    "\n",
    "- Mantener el **modelo global** (mismas dimensiones y arquitectura que el modelo base federado MLP).\n",
    "- Coordinar las **rondas globales**:\n",
    "  - Difundir parámetros a todos los clientes.\n",
    "  - Esperar actualizaciones.\n",
    "  - Agregar parámetros.\n",
    "  - Actualizar el modelo global.\n",
    "- Registrar en logs:\n",
    "  - Métricas globales por ronda (por ejemplo, F1 promedio estimado sobre un conjunto central de validación o combinando métricas locales).\n",
    "  - Número de mensajes y bytes enviados/recibidos (costo de comunicación).\n",
    "- Manejar casos de fallo:\n",
    "  - Si un cliente no responde en una ronda, se ignora su actualización para esa ronda y se continúa con los demás.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26678031",
   "metadata": {},
   "source": [
    "### 5.3. Nodo agregador dinámico (en FL semi-descentralizado)\n",
    "\n",
    "En la topología semi-descentralizada:\n",
    "\n",
    "- No hay un servidor dedicado.\n",
    "- Uno de los clientes asume el rol de **agregador** en una ronda dada.\n",
    "\n",
    "Responsabilidades del agregador en la ronda `t`:\n",
    "\n",
    "1. Iniciar la ronda difundiendo el modelo global local que posee.\n",
    "2. Recibir parámetros de los otros nodos.\n",
    "3. Aplicar la función de **agregación** (FedAvg ponderado, o la estrategia alternativa).\n",
    "4. Actualizar su copia del modelo global.\n",
    "5. Difundir el modelo global actualizado a todos los clientes.\n",
    "\n",
    "En la práctica, cada nodo cliente deberá tener la lógica necesaria para:\n",
    "\n",
    "- Actuar como **cliente normal** en las rondas donde no le toca agregar.\n",
    "- Actuar como **agregador** cuando es seleccionado por la política de rotación (round-robin).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85d529d",
   "metadata": {},
   "source": [
    "## 6. Mensajes y protocolo de comunicación\n",
    "\n",
    "A nivel de implementación, vamos a usar **sockets TCP** y **JSON** como formato de serialización.\n",
    "\n",
    "- TCP nos da un canal confiable (sin pérdida de mensajes).\n",
    "- JSON es fácil de depurar y suficiente para el tamaño de modelos que manejamos (MLP pequeño).\n",
    "\n",
    "### 6.1. Tipos de mensajes\n",
    "\n",
    "Definimos los siguientes tipos lógicos de mensaje:\n",
    "\n",
    "1. `INIT_CONFIG`\n",
    "   - Se envía al inicio del experimento.\n",
    "   - Permite compartir:\n",
    "     - IDs de los nodos.\n",
    "     - Número total de rondas.\n",
    "     - Hiperparámetros globales (epochs locales, batch size, etc.).\n",
    "\n",
    "2. `GLOBAL_MODEL`\n",
    "   - El servidor (o agregador) envía el **modelo global actual** a los clientes.\n",
    "   - Contiene:\n",
    "     - `round_id`\n",
    "     - `model_name` (por ejemplo, `\"mlp_federated_baseline\"`)\n",
    "     - `weights` y `biases` serializados.\n",
    "\n",
    "3. `LOCAL_UPDATE`\n",
    "   - El cliente envía su actualización local tras entrenar.\n",
    "   - Contiene:\n",
    "     - `round_id`\n",
    "     - `client_id`\n",
    "     - `n_samples`\n",
    "     - `weights` y `biases` actualizados.\n",
    "     - Métricas locales opcionales (`f1_local`, `loss_local`, etc.).\n",
    "\n",
    "4. `AGGREGATED_MODEL`\n",
    "   - El servidor (o agregador) difunde el **modelo agregado** tras combinar las actualizaciones.\n",
    "   - Estructura similar a `GLOBAL_MODEL`.\n",
    "\n",
    "5. `HEARTBEAT` / `ACK`\n",
    "   - Mensajes ligeros para confirmar que los nodos están vivos y que recibieron correctamente un paquete importante.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d72689",
   "metadata": {},
   "source": [
    "### 6.2. Formato de los parámetros del modelo (MLP federado)\n",
    "\n",
    "El modelo base federado que vamos a usar es equivalente al `MLPClassifier` central ya entrenado:\n",
    "\n",
    "- Una capa oculta de tamaño moderado (por ejemplo `(32,)`).\n",
    "- Activación ReLU.\n",
    "- Capa de salida con una neurona (clasificación binaria).\n",
    "\n",
    "En scikit-learn, los parámetros del MLP se almacenan como:\n",
    "\n",
    "- `coefs_`   → lista de matrices de pesos por capa.\n",
    "- `intercepts_` → lista de vectores de sesgos por capa.\n",
    "\n",
    "Para poder enviarlos por JSON, haremos:\n",
    "\n",
    "1. Convertir cada matriz/ vector en una **lista anidada de floats** (con `.tolist()`).\n",
    "2. Enviar también la **forma** (`shape`) de cada matriz para reconstruirla fácilmente.\n",
    "\n",
    "Un ejemplo de estructura JSON para los parámetros sería:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"round_id\": 3,\n",
    "  \"model_name\": \"mlp_federated_baseline\",\n",
    "  \"weights\": [\n",
    "    {\n",
    "      \"name\": \"W1\",\n",
    "      \"shape\": [n_features, 32],\n",
    "      \"values\": [[...], [...], ...]\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"b1\",\n",
    "      \"shape\": [32],\n",
    "      \"values\": [...]\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"W2\",\n",
    "      \"shape\": [32, 1],\n",
    "      \"values\": [[...], ...]\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"b2\",\n",
    "      \"shape\": [1],\n",
    "      \"values\": [...]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "A nivel de implementación, tendremos funciones auxiliares para:\n",
    "\n",
    "- **Extraer parámetros** del modelo MLP de scikit-learn y convertirlos a un diccionario serializable.\n",
    "- **Reconstruir parámetros** a partir del diccionario recibido y asignarlos al modelo local.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08cbfb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esqueleto (aún sin implementación concreta) de cómo se verían las funciones auxiliares\n",
    "# para extraer y cargar parámetros del modelo MLP federado.\n",
    "\n",
    "def extract_mlp_parameters(mlp_model):\n",
    "    \"\"\"Convierte coefs_ e intercepts_ de un MLP de scikit-learn a un dict serializable por JSON.\"\"\"\n",
    "    params = []\n",
    "    for i, (w, b) in enumerate(zip(mlp_model.coefs_, mlp_model.intercepts_)):\n",
    "        params.append({\n",
    "            \"name\": f\"W{i+1}\",\n",
    "            \"shape\": list(w.shape),\n",
    "            \"values\": w.tolist(),\n",
    "        })\n",
    "        params.append({\n",
    "            \"name\": f\"b{i+1}\",\n",
    "            \"shape\": list(b.shape),\n",
    "            \"values\": b.tolist(),\n",
    "        })\n",
    "    return params\n",
    "\n",
    "\n",
    "def load_mlp_parameters(mlp_model, params):\n",
    "    \"\"\"Carga parámetros en un MLP de scikit-learn a partir de un dict serializable.\"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    coefs = []\n",
    "    intercepts = []\n",
    "    # Asumimos que params viene en orden [W1, b1, W2, b2, ...]\n",
    "    for i in range(0, len(params), 2):\n",
    "        W_info = params[i]\n",
    "        b_info = params[i + 1]\n",
    "        coefs.append(np.array(W_info[\"values\"], dtype=float))\n",
    "        intercepts.append(np.array(b_info[\"values\"], dtype=float))\n",
    "\n",
    "    mlp_model.coefs_ = coefs\n",
    "    mlp_model.intercepts_ = intercepts\n",
    "    return mlp_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485e1f65",
   "metadata": {},
   "source": [
    "Estas funciones **no se usan todavía** en este notebook, pero dejan claro el tipo de serialización que se implementará después en los scripts de servidor y clientes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2076266f",
   "metadata": {},
   "source": [
    "## 7. Rondas globales y sincronización\n",
    "\n",
    "El entrenamiento federado se organiza en **rondas globales** numeradas `t = 1, 2, ..., T`.\n",
    "\n",
    "### 7.1. Parámetros de alto nivel (configuración global)\n",
    "\n",
    "Definimos algunos hiperparámetros que se mantendrán consistentes entre las implementaciones:\n",
    "\n",
    "- `N_CLIENTS`      → número de nodos clientes (en nuestro caso, 3 hospitales).\n",
    "- `GLOBAL_ROUNDS`  → número total de rondas globales `T`.\n",
    "- `LOCAL_EPOCHS`   → número de épocas de entrenamiento local en cada ronda (por ejemplo, 1–5).\n",
    "- `BATCH_SIZE`     → tamaño de mini-batch en el entrenamiento local.\n",
    "- `AGG_STRATEGY`   → estrategia de agregación (`\"fedavg_weighted\"` o `\"fedavg_uniform\"`).\n",
    "- `AGG_POLICY`     → política de selección de agregador en el caso semi-descentralizado (`\"fixed_server\"` o `\"round_robin\"`).\n",
    "\n",
    "Guardamos un pequeño diccionario de configuración que luego podremos reutilizar:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b1507b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'N_CLIENTS': 3,\n",
       " 'CLIENT_IDS': ['Hospital_1', 'Hospital_2', 'Hospital_3'],\n",
       " 'GLOBAL_ROUNDS': 10,\n",
       " 'LOCAL_EPOCHS': 3,\n",
       " 'BATCH_SIZE': 64,\n",
       " 'AGG_STRATEGY': 'fedavg_weighted',\n",
       " 'AGG_POLICY': 'fixed_server'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GLOBAL_CONFIG = {\n",
    "    \"N_CLIENTS\": 3,\n",
    "    \"CLIENT_IDS\": [\"Hospital_1\", \"Hospital_2\", \"Hospital_3\"],\n",
    "    \"GLOBAL_ROUNDS\": 10,\n",
    "    \"LOCAL_EPOCHS\": 3,\n",
    "    \"BATCH_SIZE\": 64,\n",
    "    \"AGG_STRATEGY\": \"fedavg_weighted\",  # alternativa: \"fedavg_uniform\"\n",
    "    \"AGG_POLICY\": \"fixed_server\",       # alternativa: \"round_robin\" (semi-descentralizado)\n",
    "}\n",
    "\n",
    "GLOBAL_CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c813508",
   "metadata": {},
   "source": [
    "Este diccionario es solo una plantilla. En la implementación real lo ajustaremos según los experimentos.\n",
    "\n",
    "### 7.2. Ciclo de una ronda global en FL centralizado\n",
    "\n",
    "En el caso de **FL centralizado**, una ronda global `t` se ve así:\n",
    "\n",
    "1. **Broadcast del modelo global**\n",
    "   - El servidor envía el modelo global actual a todos los clientes en un mensaje `GLOBAL_MODEL`.\n",
    "\n",
    "2. **Entrenamiento local**\n",
    "   - Cada cliente:\n",
    "     - Reconstruye el modelo local a partir de los parámetros recibidos.\n",
    "     - Entrena localmente `LOCAL_EPOCHS` épocas con sus datos.\n",
    "     - Calcula métricas locales (opcional).\n",
    "\n",
    "3. **Envío de actualizaciones**\n",
    "   - Cada cliente envía un mensaje `LOCAL_UPDATE` al servidor con:\n",
    "     - `round_id = t`\n",
    "     - `client_id`\n",
    "     - `n_samples`\n",
    "     - `params` (lista de pesos y sesgos serializados)\n",
    "     - Métricas locales opcionales.\n",
    "\n",
    "4. **Agregación**\n",
    "   - El servidor espera actualizaciones de todos los clientes (o de una fracción mínima configurada).\n",
    "   - Aplica la función de agregación seleccionada (`AGG_STRATEGY`).\n",
    "   - Actualiza el modelo global.\n",
    "\n",
    "5. **Registro de resultados**\n",
    "   - El servidor registra métricas globales para la ronda `t`.\n",
    "   - Opcionalmente, evalúa el modelo global en un subconjunto de validación central.\n",
    "\n",
    "Luego pasa a la ronda `t+1` hasta completar `GLOBAL_ROUNDS`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bd0005",
   "metadata": {},
   "source": [
    "### 7.3. Ciclo de una ronda global en FL semi-descentralizado\n",
    "\n",
    "En el **FL semi-descentralizado** con política `round_robin`:\n",
    "\n",
    "- El conjunto de clientes es el mismo (`Hospital_1`, `Hospital_2`, `Hospital_3`).\n",
    "- En cada ronda `t` elegimos un **agregador** distinto, por ejemplo:\n",
    "\n",
    "  - Ronda 1 → `Hospital_1`\n",
    "  - Ronda 2 → `Hospital_2`\n",
    "  - Ronda 3 → `Hospital_3`\n",
    "  - Ronda 4 → `Hospital_1` (y así sucesivamente)\n",
    "\n",
    "El ciclo de la ronda `t` es:\n",
    "\n",
    "1. El agregador `A_t` difunde el modelo global actual (que guarda localmente) en un mensaje `GLOBAL_MODEL`.\n",
    "2. Todos los nodos (incluyendo `A_t`) entrenan localmente y generan sus `LOCAL_UPDATE`.\n",
    "3. Los clientes envían sus actualizaciones de vuelta a `A_t`.\n",
    "4. `A_t` aplica la estrategia de agregación (`AGG_STRATEGY`) y actualiza su modelo global.\n",
    "5. `A_t` difunde el modelo global actualizado a los demás nodos.\n",
    "\n",
    "En la práctica, toda la lógica de agregación que antes estaba en el servidor se moverá al nodo que toque según `AGG_POLICY = \"round_robin\"`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30776d36",
   "metadata": {},
   "source": [
    "## 8. Estrategias de agregación a comparar\n",
    "\n",
    "La rúbrica del proyecto pide **comparar al menos dos estrategias de agregación**.\n",
    "\n",
    "En este trabajo vamos a comparar:\n",
    "\n",
    "1. **FedAvg ponderado por número de muestras** (`fedavg_weighted`)\n",
    "2. **Promedio simple no ponderado** (`fedavg_uniform`)\n",
    "\n",
    "### 8.1. FedAvg ponderado (`fedavg_weighted`)\n",
    "\n",
    "Sea \\(K\\) el número de clientes participantes en una ronda, y \\(w_k\\) los parámetros del modelo del cliente \\(k\\) después del entrenamiento local, con \\(n_k\\) muestras usadas.\n",
    "\n",
    "La actualización global es:\n",
    "\n",
    "\\[\n",
    "w^{(t+1)} = \\frac{\\sum_{k=1}^K n_k \\, w_k}{\\sum_{k=1}^K n_k}\n",
    "\\]\n",
    "\n",
    "Es decir, cada cliente pesa proporcionalmente a la cantidad de datos que aporta.\n",
    "\n",
    "Ventajas:\n",
    "\n",
    "- Se parece a entrenar con todos los datos mezclados: los nodos grandes tienen más peso en la actualización.\n",
    "- Suele maximizar el desempeño global cuando el objetivo principal es minimizar la pérdida promedio sobre todos los registros.\n",
    "\n",
    "Desventajas:\n",
    "\n",
    "- Los nodos pequeños pueden quedar subrepresentados (menor influencia en el modelo global)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5ca6d2",
   "metadata": {},
   "source": [
    "### 8.2. Promedio simple (`fedavg_uniform`)\n",
    "\n",
    "En la variante de promedio simple no ponderado, la actualización es:\n",
    "\n",
    "\\[\n",
    "w^{(t+1)} = \\frac{1}{K} \\sum_{k=1}^K w_k\n",
    "\\]\n",
    "\n",
    "Todos los clientes tienen el mismo peso, independientemente del tamaño de su conjunto de datos.\n",
    "\n",
    "Ventajas:\n",
    "\n",
    "- Más sencillo conceptualmente.\n",
    "- Da más peso relativo a los nodos pequeños (útil si queremos cierta noción de equidad entre hospitales).\n",
    "\n",
    "Desventajas:\n",
    "\n",
    "- Desde el punto de vista de la pérdida global, puede ser subóptimo si los tamaños de los nodos difieren mucho.\n",
    "\n",
    "En el paper podremos comparar ambos enfoques en términos de:\n",
    "\n",
    "- F1 global en test (comparado contra el modelo centralizado).\n",
    "- Variación de métricas por hospital.\n",
    "- Costo de comunicación (igual en ambos casos, pero podemos comentar si la convergencia difiere)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3dfd990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_fedavg_weighted(client_updates):\n",
    "    \"\"\"Esqueleto de agregación FedAvg ponderado.\n",
    "    client_updates: lista de dicts con claves:\n",
    "        - 'n_samples'\n",
    "        - 'params'  (lista de pesos y biases)\n",
    "    Aquí solo dejamos la firma; la implementación real irá en los scripts de FL.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "def aggregate_fedavg_uniform(client_updates):\n",
    "    \"\"\"Esqueleto de agregación usando promedio simple (no ponderado).\"\"\"\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39164078",
   "metadata": {},
   "source": [
    "Estas firmas dejan claro que:\n",
    "\n",
    "- Recibiremos una lista de actualizaciones, una por cliente.\n",
    "- Cada entrada tendrá al menos `n_samples` y la lista de parámetros serializados.\n",
    "- Tendremos dos funciones separadas para cambiar fácilmente de estrategia en los experimentos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d722d2",
   "metadata": {},
   "source": [
    "## 9. Métricas y logging para comparar arquitecturas\n",
    "\n",
    "Para que la comparación entre arquitecturas sea consistente, usaremos el mismo conjunto de métricas que en el escenario centralizado:\n",
    "\n",
    "- **Accuracy**\n",
    "- **Precision**\n",
    "- **Recall**\n",
    "- **F1-score** (métrica principal)\n",
    "- **ROC AUC**\n",
    "- Matrices de confusión y curvas ROC / Precision-Recall (en el notebook de resultados).\n",
    "\n",
    "Además, para el caso federado vamos a registrar explícitamente:\n",
    "\n",
    "- **Tiempos de entrenamiento local** por nodo y por ronda.\n",
    "- **Tiempo de agregación** por ronda.\n",
    "- **Tamaño de los mensajes** (al menos aproximado, en bytes o kB).\n",
    "- **Número total de mensajes** intercambiados.\n",
    "\n",
    "En la práctica, tendremos una estructura de logging tipo:\n",
    "\n",
    "```python\n",
    "history = {\n",
    "    \"round\": [],\n",
    "    \"arch\": [],           # 'centralized_fl' o 'semi_decentralized_fl'\n",
    "    \"agg_strategy\": [],   # 'fedavg_weighted' o 'fedavg_uniform'\n",
    "    \"global_f1_val\": [],\n",
    "    \"global_f1_test\": [],\n",
    "    \"total_comm_bytes\": [],\n",
    "    \"train_time_sec\": [],\n",
    "    # etc.\n",
    "}\n",
    "```\n",
    "\n",
    "Esta información alimentará tanto:\n",
    "\n",
    "- Los **gráficos** de comparación (accuracy / F1 vs. ronda, pérdida vs. ronda).\n",
    "- Como las **tablas** del paper (centralizado vs FL centralizado vs FL semi-descentralizado).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
